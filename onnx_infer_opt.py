import os
import cv2
import numpy as np
import onnxruntime as ort
import argparse

# é…ç½®ä¿¡æ¯
CLASS_NAMES = {0: 'JZ', 1: 'DL'}
CLASS_COLORS = {
    0: (255, 255, 0),  # é’é»„è‰² (BGR)
    1: (0, 0, 255)  # çº¢è‰² (BGR)
}


def run_yolo11_segmentation(model_path, image_path, conf_threshold=0.5, iou_threshold=0.45,
                            use_gpu=False, visualize=True, save_path=None):
    """
    YOLO11å®ä¾‹åˆ†å‰²æ¨ç†å‡½æ•°

    Args:
        model_path (str): ONNXæ¨¡å‹è·¯å¾„
        image_path (str): è¾“å…¥å›¾ç‰‡è·¯å¾„
        conf_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
        iou_threshold (float): NMSçš„IoUé˜ˆå€¼
        use_gpu (bool): æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
        visualize (bool): æ˜¯å¦å¯è§†åŒ–ç»“æœ
        save_path (str): ä¿å­˜ç»“æœçš„è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸ä¿å­˜

    Returns:
        tuple: (boxes, segments, masks, result_image)
    """
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")

    # åˆå§‹åŒ–ONNXæ¨ç†ä¼šè¯
    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if use_gpu else ['CPUExecutionProvider']
    session = ort.InferenceSession(model_path, providers=providers)

    # è·å–æ¨¡å‹è¾“å…¥ä¿¡æ¯
    model_input = session.get_inputs()[0]
    input_name = model_input.name
    model_shape = model_input.shape
    input_height, input_width = model_shape[2], model_shape[3]
    dtype = np.float16 if model_input.type == 'tensor(float16)' else np.float32

    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
    print(f"ğŸš€ æ¨ç†åç«¯: {session.get_providers()[0]}")

    # è¯»å–å›¾åƒ
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")

    # é¢„å¤„ç†
    def preprocess(img):
        h, w = img.shape[:2]
        r = min(input_height / h, input_width / w)
        new_unpad = (int(round(w * r)), int(round(h * r)))

        img_resized = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR) if (w, h) != new_unpad else img

        dw, dh = (input_width - new_unpad[0]) / 2, (input_height - new_unpad[1]) / 2
        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

        img_padded = cv2.copyMakeBorder(img_resized, top, bottom, left, right, cv2.BORDER_CONSTANT,
                                        value=(114, 114, 114))

        img_in = img_padded.transpose(2, 0, 1)[::-1]
        img_in = np.ascontiguousarray(img_in, dtype=dtype) / 255.0
        return img_in[None], r, (left, top)

    # åå¤„ç†
    def postprocess(preds, ori_shape, ratio, pad):
        p = np.squeeze(preds[0]).T
        proto = np.squeeze(preds[1])

        scores = np.max(p[:, 4:-32], axis=1)
        mask = scores > conf_threshold
        p = p[mask]
        scores = scores[mask]

        if len(p) == 0:
            return [], [], []

        class_ids = np.argmax(p[:, 4:-32], axis=1)
        boxes = p[:, :4].copy()
        boxes[:, 0] -= boxes[:, 2] / 2  # è½¬æ¢ä¸ºä¸­å¿ƒç‚¹åæ ‡
        boxes[:, 1] -= boxes[:, 3] / 2

        indices = cv2.dnn.NMSBoxes(boxes.tolist(), scores.tolist(), conf_threshold, iou_threshold)
        if len(indices) == 0:
            return [], [], []

        indices = indices.flatten()
        p = p[indices]
        class_ids = class_ids[indices]
        scores = scores[indices]

        # å°†ä¸­å¿ƒç‚¹åæ ‡è½¬ä¸ºè§’ç‚¹åæ ‡ (xyxy)
        final_boxes = p[:, :4].copy()
        final_boxes[:, 0] -= final_boxes[:, 2] / 2  # x1
        final_boxes[:, 1] -= final_boxes[:, 3] / 2  # y1
        final_boxes[:, 2] += final_boxes[:, 0]  # x2
        final_boxes[:, 3] += final_boxes[:, 1]  # y2

        # é€†ç¼©æ”¾å’Œé€†å¡«å……å¤„ç†
        final_boxes[:, [0, 2]] -= pad[0]  # x1, x2 å‡å»å·¦å¡«å……
        final_boxes[:, [1, 3]] -= pad[1]  # y1, y2 å‡å»ä¸Šå¡«å……
        final_boxes /= ratio  # é€†ç¼©æ”¾
        final_boxes[:, [0, 2]] = final_boxes[:, [0, 2]].clip(0, ori_shape[1])  # é™åˆ¶åœ¨å›¾åƒèŒƒå›´å†…
        final_boxes[:, [1, 3]] = final_boxes[:, [1, 3]].clip(0, ori_shape[0])

        # å¤„ç†æ©ç 
        mask_coeffs = p[:, -32:]
        n, mh, mw = len(p), proto.shape[1], proto.shape[2]
        masks = (mask_coeffs @ proto.reshape(32, -1)).reshape(n, mh, mw)
        masks = 1 / (1 + np.exp(-masks))

        final_masks = []
        segments = []
        for i in range(n):
            # å°†æ©ç ä»æ¨¡å‹è¾“å‡ºå°ºå¯¸(å¦‚160x160)ç¼©æ”¾åˆ°è¾“å…¥å°ºå¯¸(å¦‚640x640)
            m = cv2.resize(masks[i], (input_width, input_height), interpolation=cv2.INTER_LINEAR)

            # å»é™¤letterboxå¡«å…… - ä½¿ç”¨ä¸è¾¹ç•Œæ¡†ç›¸åŒçš„å¡«å……å‚æ•°
            m = m[int(pad[1]):int(input_height - pad[1]), int(pad[0]):int(input_width - pad[0])]

            # ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå°ºå¯¸
            m = cv2.resize(m, (ori_shape[1], ori_shape[0]), interpolation=cv2.INTER_LINEAR)

            # äºŒå€¼åŒ–
            m = (m > 0.5).astype(np.uint8)

            # æå–è½®å»“ä½œä¸ºåˆ†å‰²åŒºåŸŸ
            contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                c = max(contours, key=len).reshape(-1, 2)
                segments.append(c)
            else:
                segments.append(np.zeros((0, 2)))
            final_masks.append(m)

        det_results = np.concatenate([final_boxes, scores[:, None], class_ids[:, None]], axis=1)
        return det_results, segments, np.array(final_masks)

    # å¯è§†åŒ–
    def draw_results(img, boxes, segments, alpha=0.4):
        visual_img = img.copy()
        mask_layer = np.zeros_like(img)

        for box, seg in zip(boxes, segments):
            cls_id = int(box[5])
            color = CLASS_COLORS.get(cls_id, (0, 255, 0))

            if seg.size > 0:
                cv2.fillPoly(mask_layer, [seg.astype(np.int32)], color)

            x1, y1, x2, y2 = box[:4].astype(np.int32)
            cv2.rectangle(visual_img, (x1, y1), (x2, y2), color, 2)
            label = f"{CLASS_NAMES.get(cls_id, 'Unknown')} {box[4]:.2f}"
            cv2.putText(visual_img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        res = cv2.addWeighted(mask_layer, alpha, visual_img, 1.0, 0)
        return res

    # æ‰§è¡Œæ¨ç†
    blob, ratio, pad = preprocess(image)
    preds = session.run(None, {input_name: blob})
    boxes, segments, masks = postprocess(preds, image.shape, ratio, pad)

    result_image = None
    if len(boxes) > 0:
        if visualize:
            result_image = draw_results(image, boxes, segments)
            cv2.imshow("YOLO11 Segmentation", result_image)
            print(f"ğŸ’¡ æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡")
            cv2.waitKey(0)
            cv2.destroyAllWindows()

        if save_path:
            if result_image is None:
                result_image = draw_results(image, boxes, segments)
            cv2.imwrite(save_path, result_image)
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°ç›®æ ‡")

    return boxes, segments, masks, result_image


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, default=r'E:\Desktop\ultralytics\runs\segment\ZY_BJ_JZ\weights\best.onnx',
                        help="ONNXæ¨¡å‹è·¯å¾„")
    parser.add_argument("--source", type=str, default=r"E:\Desktop\LR2HR\enhanced\enhanced_0000.tif",
                        help="è¾“å…¥å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--conf", type=float, default=0.5, help="ç½®ä¿¡åº¦")
    parser.add_argument("--iou", type=float, default=0.45, help="NMSé˜ˆå€¼")
    parser.add_argument("--no-gpu", action="store_true", help="ä¸ä½¿ç”¨GPU")
    parser.add_argument("--output", type=str, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    run_yolo11_segmentation(
        model_path=args.model,
        image_path=args.source,
        conf_threshold=args.conf,
        iou_threshold=args.iou,
        use_gpu=not args.no_gpu,
        save_path=args.output
    )
